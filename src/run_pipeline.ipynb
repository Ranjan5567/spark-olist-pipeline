{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362009ea-5719-459d-af06-bb51df5c727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = r\"C:\\Users\\ranjan\\Desktop\\spark-olist-pipeline\\venv\\Scripts\\python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = r\"C:\\Users\\ranjan\\Desktop\\spark-olist-pipeline\\venv\\Scripts\\python.exe\"\n",
    "os.environ[\"spark.python.worker.reuse\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5e2947-2b38-4208-8f02-a887a071cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../src\")) \n",
    "from bronze import create_spark_session, ingest_csv\n",
    "\n",
    "spark = create_spark_session(\"OlistPipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56822a80-2de1-4fc4-8063-7e84abe71f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Query Execution Enabled: true\n"
     ]
    }
   ],
   "source": [
    "# Check AQE\n",
    "print(\"Adaptive Query Execution Enabled:\", spark.conf.get(\"spark.sql.adaptive.enabled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6110909-cc86-499f-a051-78fd144d56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_input = \"../data/\"\n",
    "base_output = \"../../delta/bronze/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c7fb8c-cc50-4f9c-ab3e-492ec14bd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bronze ingestion for all Olist tables\n",
    "datasets = {\n",
    "    \"customers\": \"olist_customers_dataset.csv\",\n",
    "    \"orders\": \"olist_orders_dataset.csv\",\n",
    "    \"order_items\": \"olist_order_items_dataset.csv\",\n",
    "    \"order_payments\": \"olist_order_payments_dataset.csv\",\n",
    "    \"order_reviews\": \"olist_order_reviews_dataset.csv\",\n",
    "    \"products\": \"olist_products_dataset.csv\",\n",
    "    \"sellers\": \"olist_sellers_dataset.csv\",\n",
    "    \"geolocation\": \"olist_geolocation_dataset.csv\",\n",
    "    \"category_translation\": \"product_category_name_translation.csv\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c559f99-b54b-4fad-99e8-8c589a2e0920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Ingesting customers → ../../delta/bronze/customers\n"
     ]
    }
   ],
   "source": [
    "for name, filename in datasets.items():\n",
    "    input_path = f\"{base_input}{filename}\"\n",
    "    output_path = f\"{base_output}{name}\"\n",
    "\n",
    "    print(f\"\\n[INFO] Ingesting {name} → {output_path}\")\n",
    "    \n",
    "    if name == \"orders\":  # partition only orders\n",
    "        ingest_csv(spark, input_path, output_path, partition_col=\"order_purchase_month\", target_file_rows=50000)\n",
    "    else:\n",
    "        ingest_csv(spark, input_path, output_path, target_file_rows=50000)\n",
    "\n",
    "    # Read back from Delta & show\n",
    "    df = spark.read.format(\"delta\").load(output_path)\n",
    "    print(f\"[INFO] Showing {name} table (first 5 rows):\")\n",
    "    df.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221fa00-832e-4f7c-afcf-7051b21d0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bronze layer  ingestion completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6a1a4-c857-4234-934b-d3fb38f4476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_output = \"../delta/silver/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c41411f-82ae-4337-bda3-3f21d49d2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curate Silver Layer\n",
    "curate_sales(spark, bronze_base=bronze_output, silver_base=silver_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fcc05f-faca-4d69-a8a4-5920398924ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Silver\n",
    "print(\"\\n[INFO] Silver Layer Sales Table:\")\n",
    "sales_df = spark.read.format(\"delta\").load(f\"{silver_output}/sales\")\n",
    "sales_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc528c09-779c-4930-9f8c-46b0a3b3fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.select(\"seller_id\", \"seller_salt\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93389931-c19e-4cae-97d2-f4b87529625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique city/state samples for customers & sellers\n",
    "silver_path = \"../delta/silver/\"\n",
    "customers_df = spark.read.format(\"delta\").load(silver_path + \"customers\")\n",
    "sellers_df = spark.read.format(\"delta\").load(silver_path + \"sellers\")\n",
    "\n",
    "print(\"Customer city samples:\", [row.customer_city for row in customers_df.select(\"customer_city\").distinct().limit(5).collect()])\n",
    "print(\"Customer state samples:\", [row.customer_state for row in customers_df.select(\"customer_state\").distinct().limit(5).collect()])\n",
    "\n",
    "print(\"Seller city samples:\", [row.seller_city for row in sellers_df.select(\"seller_city\").distinct().limit(5).collect()])\n",
    "print(\"Seller state samples:\", [row.seller_state for row in sellers_df.select(\"seller_state\").distinct().limit(5).collect()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182f338-b320-46f5-ace3-fee2aead8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicate customers:\", customers_df.count() - customers_df.dropDuplicates([\"customer_id\"]).count())\n",
    "print(\"Duplicate sellers:\", sellers_df.count() - sellers_df.dropDuplicates([\"seller_id\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88442390-509d-4db9-a7ec-b51db6516130",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = spark.read.format(\"delta\").load(silver_path + \"sales\")\n",
    "\n",
    "print(\"Sample seller_id_salted:\")\n",
    "sales_df.select(\"seller_salt\").distinct().show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436af91-3b5f-4880-9e75-c91f1d2c2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
