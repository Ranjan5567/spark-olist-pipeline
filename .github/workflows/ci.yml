name: CI - Spark Olist Pipeline

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

jobs:
  build-and-test:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python-version: [3.10.11]

    steps:
      # Step 1: Checkout repository
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install jupyter nbconvert delta-spark chispa
      # Step 4: Run Pytest
      - name: Run unit tests
        run: |
          pytest -v --disable-warnings
      # Step 5: Run full pipeline notebook
      - name: Run pipeline notebook
        run: |
          mkdir -p /tmp/delta  # temp folders for bronze/silver/gold
          export PYTHONPATH=$PYTHONPATH:$(pwd)/src
          ls src               # debug: confirm notebook exists
          jupyter nbconvert --to notebook --execute src/run_pipeline.ipynb \
            --output /tmp/run_pipeline_out.ipynb \
            --ExecutePreprocessor.timeout=1200
      # Step 6: Upload executed notebook as artifact
      - name: Upload executed notebook
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-notebook
          path: /tmp/run_pipeline_out.ipynb
